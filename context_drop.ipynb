{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b761e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['29']\n",
      "['31']\n",
      "['27']\n",
      "['27']\n",
      "['34']\n",
      "['32']\n",
      "['28']\n",
      "['29']\n",
      "['33']\n",
      "['33']\n",
      "[]\n",
      "['33']\n",
      "['27']\n",
      "['28']\n",
      "['29']\n",
      "['27']\n",
      "['28']\n",
      "['31']\n",
      "['31']\n",
      "['30']\n",
      "['31']\n",
      "[]\n",
      "['28']\n",
      "['31']\n",
      "['32']\n",
      "['27']\n",
      "['31']\n",
      "['33']\n",
      "['27']\n",
      "['32']\n",
      "['34']\n",
      "['34']\n",
      "['34']\n",
      "['32']\n",
      "['32']\n",
      "['31']\n",
      "['33']\n",
      "['31']\n",
      "['28']\n",
      "['29']\n",
      "['28']\n",
      "['32']\n",
      "['34']\n",
      "['30']\n",
      "['32']\n",
      "['31']\n",
      "['30']\n",
      "['30']\n",
      "['29']\n",
      "['34']\n",
      "['31']\n",
      "['32']\n",
      "['32']\n",
      "['31']\n",
      "['28']\n",
      "['31']\n",
      "['27']\n",
      "['27']\n",
      "['32']\n",
      "['29']\n",
      "['28']\n",
      "['30']\n",
      "['31']\n",
      "['32']\n",
      "['31']\n",
      "['33']\n",
      "['34']\n",
      "['30']\n",
      "['33']\n",
      "['28']\n",
      "['27']\n",
      "['34']\n",
      "['32']\n",
      "['34']\n",
      "['32']\n",
      "['27']\n",
      "['34']\n",
      "['32']\n",
      "['32']\n",
      "['33']\n",
      "['30']\n",
      "['28']\n",
      "['34']\n",
      "['28']\n",
      "['34']\n",
      "['34']\n",
      "['27']\n",
      "['27']\n",
      "['32']\n",
      "['32']\n",
      "['29']\n",
      "['33']\n",
      "['28']\n",
      "['28']\n",
      "['29']\n",
      "['29']\n",
      "['28']\n",
      "['29']\n",
      "['32']\n",
      "['33']\n",
      "['27']\n",
      "['28']\n",
      "解析结果:\n",
      "                                           filename       detector  pr_auc  \\\n",
      "0       contextual_anomaly_scores_LOF_k50_c0.05.txt  LOF_k50_c0.05  0.2346   \n",
      "1     contextual_anomaly_scores_LOF_k50_c0.05_1.txt  LOF_k50_c0.05  0.2346   \n",
      "2    contextual_anomaly_scores_LOF_k50_c0.05_10.txt  LOF_k50_c0.05  0.2213   \n",
      "3    contextual_anomaly_scores_LOF_k50_c0.05_11.txt  LOF_k50_c0.05  0.2071   \n",
      "4    contextual_anomaly_scores_LOF_k50_c0.05_12.txt  LOF_k50_c0.05  0.2206   \n",
      "..                                              ...            ...     ...   \n",
      "99    contextual_anomaly_scores_LOF_k60_c0.05_1.txt  LOF_k60_c0.05  0.2185   \n",
      "100   contextual_anomaly_scores_LOF_k60_c0.05_2.txt  LOF_k60_c0.05  0.2106   \n",
      "101   contextual_anomaly_scores_LOF_k60_c0.05_3.txt  LOF_k60_c0.05  0.2107   \n",
      "102     contextual_anomaly_scores_LOF_k75_cauto.txt  LOF_k75_cauto  0.1737   \n",
      "103   contextual_anomaly_scores_LOF_k75_cauto_1.txt  LOF_k75_cauto  0.2192   \n",
      "\n",
      "     precision_at_50  context_count  \n",
      "0               0.78            NaN  \n",
      "1               0.78            NaN  \n",
      "2               0.58           29.0  \n",
      "3               0.50           31.0  \n",
      "4               0.54           27.0  \n",
      "..               ...            ...  \n",
      "99              0.74           29.0  \n",
      "100             0.68           32.0  \n",
      "101             0.68           33.0  \n",
      "102             0.02           27.0  \n",
      "103             0.04           28.0  \n",
      "\n",
      "[104 rows x 5 columns]\n",
      "\n",
      "展开后的DataFrame:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "def parse_contextual_anomaly_files(folder_path: str, prefix: str = \"contextual_anomaly_scores\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    解析具有相同前缀的上下文异常分数文件，并创建DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    folder_path : str\n",
    "        包含txt文件的文件夹路径\n",
    "    prefix : str\n",
    "        文件前缀，默认为\"contextual_anomaly_scores\"\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        包含所有文件数据的DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # 存储所有文件数据的列表\n",
    "    data_list = []\n",
    "    \n",
    "    # 遍历文件夹中的所有文件\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.startswith(prefix) and filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                \n",
    "                # 解析文件内容\n",
    "                file_data = parse_single_file_content(content, filename)\n",
    "                if file_data:\n",
    "                    data_list.append(file_data)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {filename}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # 创建DataFrame\n",
    "    if data_list:\n",
    "        df = pd.DataFrame(data_list)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No valid files found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def parse_single_file_content(content: str, filename: str) -> Dict:\n",
    "    \"\"\"\n",
    "    解析单个文件的内容\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    content : str\n",
    "        文件内容\n",
    "    filename : str\n",
    "        文件名\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict\n",
    "        包含解析数据的字典\n",
    "    \"\"\"\n",
    "    \n",
    "    # 初始化数据字典\n",
    "    file_data = {\n",
    "        'filename': filename,\n",
    "        'detector': None,\n",
    "        'pr_auc': None,\n",
    "        'precision_at_50': None,\n",
    "        'context_list': [],\n",
    "        'context_count': None\n",
    "    }\n",
    "    \n",
    "    # 分割内容为行\n",
    "    lines = content.strip().split('\\n')\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        \n",
    "        # 解析检测器名称\n",
    "        if line.startswith('Best Detector:'):\n",
    "            file_data['detector'] = line.replace('Best Detector:', '').strip()\n",
    "        \n",
    "        # 解析PR-AUC\n",
    "        elif line.startswith('PR-AUC:'):\n",
    "            pr_auc_str = line.replace('PR-AUC:', '').strip()\n",
    "            try:\n",
    "                file_data['pr_auc'] = float(pr_auc_str)\n",
    "            except ValueError:\n",
    "                print(f\"Warning: Could not parse PR-AUC value in {filename}\")\n",
    "        \n",
    "        # 解析Precision@50\n",
    "        elif line.startswith('Precision@50:'):\n",
    "            precision_str = line.replace('Precision@50:', '').strip()\n",
    "            try:\n",
    "                file_data['precision_at_50'] = float(precision_str)\n",
    "            except ValueError:\n",
    "                print(f\"Warning: Could not parse Precision@50 value in {filename}\")\n",
    "        \n",
    "        # 解析上下文列表（以方括号开头的行）\n",
    "        elif line.startswith('['):\n",
    "            # 提取列表内容\n",
    "            list_content = line.strip('[]')\n",
    "            # 分割列表项\n",
    "            context_items = [item.strip().strip(\"'\\\"\") for item in list_content.split(', ')]\n",
    "            file_data['context_list'] = context_items\n",
    "            \n",
    "            # 最后两个数字为上下文数量\n",
    "            line_digit = line[line.rfind(']') + 1:].strip()\n",
    "            digits = re.findall(r'\\d+', line_digit)\n",
    "            print(digits)\n",
    "            if digits:\n",
    "                file_data['context_count'] = int(digits[-1])\n",
    "    \n",
    "    return file_data\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 指定文件夹路径\n",
    "    folder_path = \".\"  # 替换为你的文件夹路径\n",
    "    \n",
    "    # 解析文件\n",
    "    df = parse_contextual_anomaly_files(folder_path)\n",
    "    \n",
    "    if not df.empty:\n",
    "        print(\"解析结果:\")\n",
    "        print(df[['filename', 'detector', 'pr_auc', 'precision_at_50', 'context_count']])\n",
    "        \n",
    "        # 展开上下文列表\n",
    "        # file_data = (df)\n",
    "        print(\"\\n展开后的DataFrame:\")\n",
    "        # print(file_data.head())\n",
    "        \n",
    "        # 保存到CSV文件（可选）\n",
    "        # expanded_df.to_csv('contextual_anomaly_analysis.csv', index=False)\n",
    "        # print(\"\\n结果已保存到 contextual_anomaly_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ffb12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>detector</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>precision_at_50</th>\n",
       "      <th>context_list</th>\n",
       "      <th>context_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_73.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>0.48</td>\n",
       "      <td>[age_treatment_middle_no_treatment, special_on...</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_94.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2662</td>\n",
       "      <td>0.76</td>\n",
       "      <td>[age_treatment_elderly_post_treatment, age_sex...</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_60.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>0.70</td>\n",
       "      <td>[age_sex_middle_0.0, age_sex_senior_0.0, age_t...</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_7.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.76</td>\n",
       "      <td>[age_sex_young_0.0, age_treatment_elderly_on_t...</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_34.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2570</td>\n",
       "      <td>0.66</td>\n",
       "      <td>[age_sex_middle_1.0, special_only_on_lithium, ...</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_80.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2555</td>\n",
       "      <td>0.74</td>\n",
       "      <td>[age_treatment_young_no_treatment, treatment_o...</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_86.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.58</td>\n",
       "      <td>[age_treatment_senior_no_treatment, treatment_...</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_67.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>0.70</td>\n",
       "      <td>[sex_special_1.0_general, age_sex_young_1.0, s...</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_8.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2509</td>\n",
       "      <td>0.64</td>\n",
       "      <td>[special_only_on_lithium, sex_special_1.0_on_l...</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_20.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2509</td>\n",
       "      <td>0.64</td>\n",
       "      <td>[age_treatment_senior_no_treatment, treatment_...</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_28.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.44</td>\n",
       "      <td>[age_sex_young_0.0, age_treatment_elderly_on_t...</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_44.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.64</td>\n",
       "      <td>[age_treatment_elderly_on_thyroxine, age_treat...</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_32.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2461</td>\n",
       "      <td>0.64</td>\n",
       "      <td>[age_treatment_young_no_treatment, age_treatme...</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_61.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2447</td>\n",
       "      <td>0.40</td>\n",
       "      <td>[age_sex_elderly_1.0, age_treatment_middle_on_...</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_53.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.66</td>\n",
       "      <td>[age_treatment_senior_on_antithyroid, age_trea...</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_38.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.70</td>\n",
       "      <td>[age_sex_elderly_0.0, age_treatment_middle_pos...</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_40.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.66</td>\n",
       "      <td>[age_treatment_young_on_thyroxine, age_treatme...</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_91.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.54</td>\n",
       "      <td>[age_treatment_senior_on_antithyroid, age_trea...</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_45.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>0.56</td>\n",
       "      <td>[age_treatment_senior_no_treatment, age_treatm...</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>contextual_anomaly_scores_LOF_k50_c0.05_79.txt</td>\n",
       "      <td>LOF_k50_c0.05</td>\n",
       "      <td>0.2381</td>\n",
       "      <td>0.76</td>\n",
       "      <td>[age_treatment_young_on_thyroxine, age_sex_sen...</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          filename       detector  pr_auc  \\\n",
       "0   contextual_anomaly_scores_LOF_k50_c0.05_73.txt  LOF_k50_c0.05  0.2673   \n",
       "1   contextual_anomaly_scores_LOF_k50_c0.05_94.txt  LOF_k50_c0.05  0.2662   \n",
       "2   contextual_anomaly_scores_LOF_k50_c0.05_60.txt  LOF_k50_c0.05  0.2582   \n",
       "3    contextual_anomaly_scores_LOF_k50_c0.05_7.txt  LOF_k50_c0.05  0.2576   \n",
       "4   contextual_anomaly_scores_LOF_k50_c0.05_34.txt  LOF_k50_c0.05  0.2570   \n",
       "5   contextual_anomaly_scores_LOF_k50_c0.05_80.txt  LOF_k50_c0.05  0.2555   \n",
       "6   contextual_anomaly_scores_LOF_k50_c0.05_86.txt  LOF_k50_c0.05  0.2542   \n",
       "7   contextual_anomaly_scores_LOF_k50_c0.05_67.txt  LOF_k50_c0.05  0.2530   \n",
       "8    contextual_anomaly_scores_LOF_k50_c0.05_8.txt  LOF_k50_c0.05  0.2509   \n",
       "9   contextual_anomaly_scores_LOF_k50_c0.05_20.txt  LOF_k50_c0.05  0.2509   \n",
       "10  contextual_anomaly_scores_LOF_k50_c0.05_28.txt  LOF_k50_c0.05  0.2508   \n",
       "11  contextual_anomaly_scores_LOF_k50_c0.05_44.txt  LOF_k50_c0.05  0.2467   \n",
       "12  contextual_anomaly_scores_LOF_k50_c0.05_32.txt  LOF_k50_c0.05  0.2461   \n",
       "13  contextual_anomaly_scores_LOF_k50_c0.05_61.txt  LOF_k50_c0.05  0.2447   \n",
       "14  contextual_anomaly_scores_LOF_k50_c0.05_53.txt  LOF_k50_c0.05  0.2444   \n",
       "15  contextual_anomaly_scores_LOF_k50_c0.05_38.txt  LOF_k50_c0.05  0.2440   \n",
       "16  contextual_anomaly_scores_LOF_k50_c0.05_40.txt  LOF_k50_c0.05  0.2420   \n",
       "17  contextual_anomaly_scores_LOF_k50_c0.05_91.txt  LOF_k50_c0.05  0.2419   \n",
       "18  contextual_anomaly_scores_LOF_k50_c0.05_45.txt  LOF_k50_c0.05  0.2403   \n",
       "19  contextual_anomaly_scores_LOF_k50_c0.05_79.txt  LOF_k50_c0.05  0.2381   \n",
       "\n",
       "    precision_at_50                                       context_list  \\\n",
       "0              0.48  [age_treatment_middle_no_treatment, special_on...   \n",
       "1              0.76  [age_treatment_elderly_post_treatment, age_sex...   \n",
       "2              0.70  [age_sex_middle_0.0, age_sex_senior_0.0, age_t...   \n",
       "3              0.76  [age_sex_young_0.0, age_treatment_elderly_on_t...   \n",
       "4              0.66  [age_sex_middle_1.0, special_only_on_lithium, ...   \n",
       "5              0.74  [age_treatment_young_no_treatment, treatment_o...   \n",
       "6              0.58  [age_treatment_senior_no_treatment, treatment_...   \n",
       "7              0.70  [sex_special_1.0_general, age_sex_young_1.0, s...   \n",
       "8              0.64  [special_only_on_lithium, sex_special_1.0_on_l...   \n",
       "9              0.64  [age_treatment_senior_no_treatment, treatment_...   \n",
       "10             0.44  [age_sex_young_0.0, age_treatment_elderly_on_t...   \n",
       "11             0.64  [age_treatment_elderly_on_thyroxine, age_treat...   \n",
       "12             0.64  [age_treatment_young_no_treatment, age_treatme...   \n",
       "13             0.40  [age_sex_elderly_1.0, age_treatment_middle_on_...   \n",
       "14             0.66  [age_treatment_senior_on_antithyroid, age_trea...   \n",
       "15             0.70  [age_sex_elderly_0.0, age_treatment_middle_pos...   \n",
       "16             0.66  [age_treatment_young_on_thyroxine, age_treatme...   \n",
       "17             0.54  [age_treatment_senior_on_antithyroid, age_trea...   \n",
       "18             0.56  [age_treatment_senior_no_treatment, age_treatm...   \n",
       "19             0.76  [age_treatment_young_on_thyroxine, age_sex_sen...   \n",
       "\n",
       "    context_count  \n",
       "0            28.0  \n",
       "1            28.0  \n",
       "2            31.0  \n",
       "3            33.0  \n",
       "4            31.0  \n",
       "5            32.0  \n",
       "6            28.0  \n",
       "7            31.0  \n",
       "8            34.0  \n",
       "9            33.0  \n",
       "10           30.0  \n",
       "11           31.0  \n",
       "12           32.0  \n",
       "13           27.0  \n",
       "14           30.0  \n",
       "15           34.0  \n",
       "16           32.0  \n",
       "17           32.0  \n",
       "18           28.0  \n",
       "19           27.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sort by pr_auc descending\n",
    "df = df.sort_values(by='pr_auc', ascending=False).reset_index(drop=True)\n",
    "# 选前20项\n",
    "df_top20 = df.head(20)\n",
    "display(df_top20)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
